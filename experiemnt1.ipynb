{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "bild = cv2.imread(\"data\\ped2//training//frames//01//000.jpg\")\n",
    "bild2 = cv2.imread(\"data\\ped2//training//frames//01//001.jpg\")\n",
    "import numpy as np\n",
    "\n",
    "lista = list()\n",
    "lista.append(bild)\n",
    "lista.append(bild2)\n",
    "\n",
    "lista = np.array(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "bilder = list()\n",
    "for folder in os.listdir(\"data//avenue//testing//frames\"):\n",
    "    path = os.path.join(\"data//avenue//testing//frames\",folder)\n",
    "    for img in os.listdir(path):\n",
    "        bild = os.path.join(path,img)\n",
    "        #bilder.append(cv2.imread(bild))\n",
    "        bilder.append(bild)\n",
    "\n",
    "#bilder = np.array(bilder)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.load(\"data/frame_labels_ped2_2.npy\")\n",
    "#labels = np.reshape(labels,labels.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fjant = pd.DataFrame(data={\"x_col\":bilder,\"y_col\":labels})#columns=([\"x_col\",\"y_col\"]))\n",
    "fjant[\"y_col\"] = fjant[\"y_col\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "dataget = ImageDataGenerator(rescale=1. / 255)\n",
    "train_get = dataget.flow_from_dataframe(dataframe=fjant,x_col=\"x_col\",y_col=\"y_col\",class_mode=\"sparse\",target_size=(360,240),batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "labels = np.load(\"data/frame_labels_avenue.npy\")\n",
    "labels = np.reshape(labels,labels.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noll = 0\n",
    "ett = 0\n",
    "for x in Y_test:\n",
    "    if x == 0:\n",
    "        noll += 1\n",
    "    else:\n",
    "        ett +=1\n",
    "print(\"Noll: \",noll)\n",
    "print(\"Ett: \",ett)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(bilder,labels,test_size=0.2, random_state= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nylabels = np.concatenate((labels,nollor))\n",
    "np.save(\"data/frame_labels_ped2_2.npy\",nylabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilder = bilder.reshape(bilder.shape[0],bilder.shape[1],bilder.shape[2],bilder.shape[3],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "bilder = scaler.fit_transform(bilder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.full((2550,1),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ett = bilder[0,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "batch_size = 4\n",
    "model = keras.Sequential()\n",
    "inputs = keras.Input((240, 360, 3, 1))\n",
    "#model.add(keras.layers.Conv3D(input_shape = ,activation=\"relu\",filters=64,kernel_size=3,padding=\"same\"))\n",
    "model.add(keras.layers.Conv3D(activation=\"relu\",filters=64,kernel_size=3,padding=\"same\"))(inputs)\n",
    "model.add(keras.layers.MaxPooling3D(pool_size=(2,2,1)))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Conv3D(activation=\"relu\",filters=64,kernel_size=3,padding=\"same\"))\n",
    "model.add(keras.layers.MaxPooling3D(pool_size=(2,2,1)))\n",
    "\n",
    "model.add(keras.layers.Conv3D(activation=\"relu\",filters=128,kernel_size=3,padding=\"same\"))\n",
    "model.add(keras.layers.MaxPooling3D(pool_size=(2,2,1)))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128,activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(64,activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10,activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\",metrics=keras.metrics.categorical_crossentropy)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv3D(input_shape =(240, 360, 3, 1),activation=\"relu\",filters=64,kernel_size=3,padding=\"same\"))\n",
    "model.add(keras.layers.MaxPooling3D(pool_size=(2,2,1)))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Conv3D(activation=\"relu\",filters=128,kernel_size=3,padding=\"same\"))\n",
    "model.add(keras.layers.MaxPooling3D(pool_size=(2,2,1)))\n",
    "\n",
    "model.add(keras.layers.Conv3D(activation=\"relu\",filters=128,kernel_size=2,padding=\"same\"))\n",
    "model.add(keras.layers.MaxPooling3D(pool_size=(2,2,1)))\n",
    "model.add(keras.layers.Dense(64,activation=\"relu\"))\n",
    "#model.add(keras.layers.GlobalAveragePooling3D())\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(256,activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(64,activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10,activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Conv3D,MaxPooling3D,BatchNormalization,Flatten,Input, Add\n",
    "from tensorflow.keras.models import Model\n",
    "input = Input((240,360,3,1))\n",
    "\n",
    "x = Conv3D(64,3,padding=\"same\")(input)\n",
    "x = MaxPooling3D(pool_size=(3,3,3))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128)(x)\n",
    "\n",
    "#y = Dense(128)(input)\n",
    "y = Flatten()(input)\n",
    "y = Dense(128)(y)\n",
    "y = Dense(128)(y)\n",
    "x = Add()([x,y])\n",
    "x = Dense(10)(x)\n",
    "x = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs = input,outputs = x)\n",
    "model.compile()\n",
    "model.summary()\n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model,show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data//UCFCrime2Local//UCFCrime2Local//Train_split_AD.txt') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import os\n",
    "from pathlib import *\n",
    "\n",
    "path = \"data/UFC\"\n",
    "\n",
    "films = list()\n",
    "files = (x for x in Path(path).iterdir() if x.is_file())\n",
    "for file in files:\n",
    "    #print(str(file.name).split(\"_\")[0], \"is a file!\")\n",
    "    films.append(str(file.name).split(\"_\")[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(lines)):\n",
    "    if lines[x].strip() != films[x]:\n",
    "        print(lines[x])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import os\n",
    "from pathlib import *\n",
    "\n",
    "path = \"data//UCFCrime2Local//UCFCrime2Local//Txt annotations\"\n",
    "\n",
    "files = (x for x in Path(path).iterdir() if x.is_file())\n",
    "for file in files:\n",
    "    films = list()\n",
    "    name = file.name.split(\".\")[0]\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            lost = int(line.split(\" \")[6])\n",
    "            if lost == 0:\n",
    "                lost = 1\n",
    "            else:\n",
    "                lost = 0\n",
    "            films.append(lost)\n",
    "        films = np.array(films)\n",
    "        np.save(os.path.join(\"data//UFC//training\",name + \".npy\"),films)\n",
    "        \n",
    "    #print(str(file.name).split(\"_\")[0], \"is a file!\")\n",
    "    #films.append(str(file.name).split(\" \")[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import os\n",
    "from pathlib import *\n",
    "\n",
    "file = \"data//UCFCrime2Local//UCFCrime2Local//Txt annotations//Burglary099.txt\"\n",
    "\n",
    "films = list()\n",
    "name = \"Burglary099\"\n",
    "with open(file) as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        lost = int(line.split(\" \")[6])\n",
    "        if lost == 0:\n",
    "            lost = 1\n",
    "        else:\n",
    "            lost = 0\n",
    "        films.append(lost)\n",
    "    films = np.array(films)\n",
    "    np.save(os.path.join(\"data//UFC//testing\",name + \".npy\"),films)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "assult = np.load(\"data//UFC//testing//NormalVideos004.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = os.listdir(\"data//UFC//training//frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = os.listdir(\"data//UFC//testing//frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for name in sub:\n",
    "    if \"Normal\" in name:\n",
    "        files = os.listdir(os.path.join(\"data//UFC//training//frames\",name))\n",
    "        name = name.split(\"_\")[0:2]\n",
    "        name = name[0] + name[1]\n",
    "        tom = np.zeros((len(files),),np.int8)\n",
    "        np.save(os.path.join(\"data//UFC//training\",name),tom)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No model found in config file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ae0d3daa509a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"flow_inception_i3d_kinetics_only_tf_dim_ordering_tf_kernels_no_top.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    204\u001b[0m       if (h5py is not None and\n\u001b[0;32m    205\u001b[0m           (isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[1;32m--> 206\u001b[1;33m         return hdf5_format.load_model_from_hdf5(filepath, custom_objects,\n\u001b[0m\u001b[0;32m    207\u001b[0m                                                 compile)\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model_config'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No model found in config file.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m     model = model_config_lib.model_from_config(model_config,\n",
      "\u001b[1;31mValueError\u001b[0m: No model found in config file."
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "\n",
    "keras.models.load_model(\"flow_inception_i3d_kinetics_only_tf_dim_ordering_tf_kernels_no_top.h5\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
